{
 "cells": [
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "6837727e",
   "metadata": {},
   "source": [
    "\n",
    "\n"
=======
   "id": "2af8cf63",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f828321",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc8c83d2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bef8c900",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05203443",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04e952ae",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8574759",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "653442fd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80e625d2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51c1465f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "768098de",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "671afdcf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1737e615",
   "metadata": {},
   "source": [
    "**函数间隔**定义为：\n",
    "\n",
    "$$\n",
    "y_{0}(w * x_{0} + b)\n",
    "$$\n",
    "\n",
    "为了能够使得确定该样本是正例还是反例的置信程度最大。当$y_{0}=1$的时候，我们希望$w * x_{0} + b$能够最大，反之则希望其最小。但是函数间隔会随着参数$w$和$b$的增大或缩小，等比例增大或缩小。"
>>>>>>> 2d43d07931c1d3dacddcacd2ee5be7ac44a20a1f
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "cb301f1c",
   "metadata": {},
   "source": [
    "分出两类数据点可以有很多条线。那如何定义一条好的线呢？\n",
    "\n",
    "- 如果我们把所有**分错的点**和直线的**距离求和**，让这段求和的**距离最小**，这条直线就是我们要找的。"
=======
   "id": "8f204790",
   "metadata": {},
   "source": [
    "**几何间隔**定义为：\n",
    "\n",
    "$$\n",
    "d=\\frac{\\left|w \\cdot x_{0}+b \\right|}{\\|w\\|}\n",
    "$$\n",
    "\n",
    "其中$\\|w\\|_{2}=\\sqrt{\\sum_{i=1}^{N}w_{i}^{2}}$。所以当$w$或者$b$等比例放大的时候，放大的参数可以单独提出来然后消掉。"
>>>>>>> 2d43d07931c1d3dacddcacd2ee5be7ac44a20a1f
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "9e11aa02",
   "metadata": {},
   "source": [
    "对于划分感知机的线我们可以描述为：\n",
    "\n",
    "1. 一条直线不分错一个点，这就是好的直线；\n",
    "2. 模型要尽可能找到好的直线；\n",
    "3. 如果没有好的直线，在差的直线中找到较好的直线；\n",
    "4. 判断直线多差的方式：分错的点到直线的距离求和。"
=======
   "id": "d87b4d0f",
   "metadata": {},
   "source": [
    "## 感知机算法的原始形式\n",
    "\n",
    "对于误分类数据而言, 有：\n",
    "\n",
    "$$\n",
    "-y_{i}(w · x_{i} + b) > 0\n",
    "$$\n",
    "\n",
    "误分类点$x_{i}$到超平面$S$的距离为：\n",
    "\n",
    "$$\n",
    "-\\frac{1}{\\|w\\|}y_{i}(w · x_{i} + b)\n",
    "$$\n",
    "\n",
    "因此，所有误分类点到超平面$S$的总距离为：\n",
    "\n",
    "$$\n",
    "-\\frac{1}{\\|w\\|} \\sum_{x_{i} \\in M}y_{i}(w · x_{i} + b)\n",
    "$$"
>>>>>>> 2d43d07931c1d3dacddcacd2ee5be7ac44a20a1f
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "45a2eb32",
   "metadata": {},
   "source": [
    "感知机模型的终极目标是学习一个函数$f(x)$:\n",
    "\n",
    "$$\n",
    "f(x) = sign(w · x + b)\n",
    "$$\n",
    "\n",
    "其中: 当$x \\geq 0$的时候, $sign(x) = + 1$; 当$x \\leq 0$的时候，$sign(x) = -1$。$w · x + b$是超平面。"
=======
   "id": "3f136e26",
   "metadata": {},
   "source": [
    "我们希望所有误分类点到超平面距离最小。可以采用梯度下降法极小化目标函数：\n",
    "\n",
    "$$\n",
    "L(w, b) = - \\sum_{x_{i} \\in M}y_{i}(w · x_{i} + b)\n",
    "$$\n",
    "\n",
    "感知机是一个误分类驱动的算法，最后是期望没有一个误分类点，所以这里采用函数间隔也没有什么大问题，因为最终的结果只是期望没有分类错误的点。如果没有分类错误的点的话，目标函数就会失效，对于整个算法目标来说，就没有什么意义了。这一点也侧面反映了感知机只能在线性可分的数据集上达到比较好的效果。\n",
    "\n",
    "对目标函数**求梯度**，我们有：\n",
    "\n",
    "$$\n",
    "\\nabla_{w} L(w, b)=-\\sum_{x_{i} \\in M} y_{i} x_{i}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\nabla_{b} L(w, b)=-\\sum_{x_{i} \\in M} y_{i}\n",
    "$$"
>>>>>>> 2d43d07931c1d3dacddcacd2ee5be7ac44a20a1f
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "2cecc959",
   "metadata": {},
   "source": [
    "## 感知机学习策略"
=======
   "id": "afb0a87b",
   "metadata": {},
   "source": [
    "最后依据梯度下降法我们可以更新参数$w$和$b$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&w \\leftarrow w+\\eta y_{i} x_{i} \\\\\n",
    "&b \\leftarrow b+\\eta y_{i}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "这里是减去一个负号，最终变成了加号。"
>>>>>>> 2d43d07931c1d3dacddcacd2ee5be7ac44a20a1f
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "7e5b908d",
   "metadata": {},
   "source": [
    "正式来说$w · x + b$是一个$n$维空间的超平面$S$, 其中$w$是超平面的法向量，$b$是超平面的截距，这个超平面将特征空间划分成两部分，位于两部分的点分别被分为正负两类，所以，超平面$S$称为分离超平面。\n",
    "\n",
    "$w$是超平面的法向量，$b$是超平面的截距，特征空间也就是整个$n$维空间，样本的每个属性都叫一个特征，**特征空间**的意思是在这个空间中可以找到样本所有的属性组合。"
=======
   "id": "c2a8e597",
   "metadata": {},
   "source": [
    "## 例子"
>>>>>>> 2d43d07931c1d3dacddcacd2ee5be7ac44a20a1f
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "f6c18b22",
   "metadata": {},
   "source": [
    "### 函数间隔\n",
    "\n"
=======
   "id": "4d5d4fa3",
   "metadata": {},
   "source": [
    "训练数据集中，正例点为$x_{1}=(3,3)^{T}$, $x_{2}=(4, 3)^{T}$, 负例点为$x_{3}=(1, 1)^{T}$。求解感知机模型$f(x)=sign(w · x + b)$, 其中$w = (w^{(1)}, w^{(2)})^{T}$, $x = (x^{(1)}, x^{(2)})^{T}$。"
>>>>>>> 2d43d07931c1d3dacddcacd2ee5be7ac44a20a1f
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "5c40f4f4",
   "metadata": {},
   "source": [
    "### 几何间隔\n",
    "\n"
=======
   "id": "41b80b4e",
   "metadata": {},
   "source": [
    "### 解"
>>>>>>> 2d43d07931c1d3dacddcacd2ee5be7ac44a20a1f
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "53850de2",
   "metadata": {},
   "source": [
    "### 超平面的构造\n",
    "\n",
    "\n"
=======
   "id": "1e34eb5b",
   "metadata": {},
   "source": [
    "1. 构建损失函数\n",
    "\n",
    "$$\n",
    "min L(w, b) = - \\sum_{x_{i} \\in M} y_{i}(w · x_{i} + b)\n",
    "$$\n",
    "\n",
    "2. 梯度下降求解$w,b$。设步长$\\eta$为1。\n",
    "\n",
    "    1) 取初值$w_{0}=0, b_{0}=0$。\n",
    "    \n",
    "    2）对于$x_{1}$而言，$y_{1}(w_{0} · x_{1} + b_{0})$未被正确分类，更新$w,b$。\n",
    "\n",
    "    此时：$w_{1}=w_{0} + x_{1}y_{1} = (3, 3)^{T}$, $b_{1}=b_{0} + y_{1}=1$，得到$w_{1}x + b_{1} = 3x^{(1)} + 3x^{(2)} + 1$。\n",
    "    \n",
    "    3） 对于$x_{1}, x_{2}$, 显然$y_{i}(w_{1}x_{i} + b_{1}) > 0$, 被正确分类，不作修改。对于$x_{3}$, $y_{3}(w_{1}x_{3} + b_{1}) < 0$, 被误分类，更新$w,b$。\n",
    "    此时：$w_{2}=w_{1} + x_{3}y_{3} = (2, 2)^{T}$, $b_{2}=b_{1} + y_{3}=0$，得到$w_{2}x + b_{2} = 2x^{(1)} + 2x^{(2)} $。"
>>>>>>> 2d43d07931c1d3dacddcacd2ee5be7ac44a20a1f
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "e9d99380",
   "metadata": {},
   "source": [
    "## 感知机的学习算法\n"
=======
   "id": "b85bc319",
   "metadata": {},
   "source": [
    "## 代码实战"
>>>>>>> 2d43d07931c1d3dacddcacd2ee5be7ac44a20a1f
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "04e4c13b",
   "metadata": {},
   "source": [
    "\n",
    "### 原始形式\n"
=======
   "id": "90b64be2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28e29e28",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d80922a9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6196a91e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b76ab016",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f06016da",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f40343b4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12c59b45",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "1. 感知机通过构造超平面的形式划分不同类的点。\n",
    "2. 感知机属于先行判别模型，因为它的判别边界是线性的。\n",
    "3. 函数间隔和几何间隔的区别。"
>>>>>>> 2d43d07931c1d3dacddcacd2ee5be7ac44a20a1f
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "4f6317c8",
   "metadata": {},
   "source": [
    "\n",
    "### 算法收敛性\n"
=======
   "id": "82070ed7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5281972a",
   "metadata": {},
   "source": [
    "## 感知机的对偶形式"
>>>>>>> 2d43d07931c1d3dacddcacd2ee5be7ac44a20a1f
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "467499bb",
   "metadata": {},
   "source": [
    "\n",
    "### 对偶形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73631fc7",
=======
   "id": "3b15c204",
   "metadata": {},
   "source": [
    "感知机的原始形式中计算存在冗余，如何快速计算感知机呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531526f7",
>>>>>>> 2d43d07931c1d3dacddcacd2ee5be7ac44a20a1f
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
