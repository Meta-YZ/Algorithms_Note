{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "305edf5a",
   "metadata": {},
   "source": [
    "## 什么是决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2181e9f",
   "metadata": {},
   "source": [
    "&emsp;&emsp;概念：基于树模型做决策；每个节点对应某个属性；每个分支对应可能的结果；叶子结点对应预测结果。\n",
    "\n",
    "&emsp;&emsp;基本流程是分而治之，自根至叶的递归过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20222aec",
   "metadata": {},
   "source": [
    "## 决策树的核心方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3059c3",
   "metadata": {},
   "source": [
    "### 自信息\n",
    "\n",
    "&emsp;&emsp;**自信息**中确定的事情信息比较少(正确的废话-男生的平均体重大于女生)。可能性小的事情信息量大。\n",
    "\n",
    "$$\n",
    "I(x) = -logP(x)\n",
    "$$\n",
    "\n",
    "&emsp;&emsp;自信息是针对单个事件进行信息量的评估，**信息熵是针对整个概率分布的信息总量进行一个描述**。均匀分布的概率分布具有较高的信息熵，接近确定性分布的具有较低的信息熵。**信息熵越小，纯度越高**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a441f484",
   "metadata": {},
   "source": [
    "### 信息熵\n",
    "\n",
    "&emsp;&emsp;构建决策树的过程是减少不确定性的过程，信息熵又可以表示为信息的不确定性的过程。设$X$是一个取有限个值的离散随机变量，其概率分布为：\n",
    "\n",
    "$$\n",
    "P(X=x_{i})=p_{i}, i=1,2,\\cdots, n\n",
    "$$\n",
    "\n",
    "&emsp;&emsp;则随机变量$X$的熵定义为：\n",
    "\n",
    "$$\n",
    "H(X) = -\\sum_{i=1}^{n} p_{i} log p_{i}\n",
    "$$\n",
    "\n",
    "&emsp;&emsp;**熵越大，则随机变量的不确定性越大**。其中$0 \\leq H(P) \\leq log n$。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cd6a04",
   "metadata": {},
   "source": [
    "### 信息熵构建决策树\n",
    "\n",
    "&emsp;&emsp;我们知道在构建决策树的过程中，1. 在根节点时，我们先假设信息熵为最大，表示一无所知。2. 到叶节点时，假设信息熵为0，表示我们非常确定。\n",
    "\n",
    "&emsp;&emsp;度量不确定性下降地快不快呢？就是通过信息增益来实现。我们希望尽可能少的次数就能够判断出结果，所以希望每个判断节点都能够让信息熵下降地快一点。**信息增益**：表示得知特征$X$的信息而使得类$Y$的信息不确定性减少的程度。\n",
    "\n",
    "\n",
    "&emsp;&emsp;但是衡量指标不一定是只有信息熵，所以这里定义一个通用的指标不纯度，如果不纯度是表示信息熵的话，上述描述就是期望不纯度降低越快越好。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721fda71",
   "metadata": {},
   "source": [
    "### 不纯度\n",
    "\n",
    "- 若记不纯度的降低程度为$\\Delta$，则用来确定划分效果的度量标准可以用以下数学公式来定义：\n",
    "\n",
    "$$\n",
    "\\Delta_{I} = I_{(parent)} - \\sum_{j=1}^{k} \\frac{N(j)}{N}I(j)\n",
    "$$\n",
    "\n",
    "&emsp;&emsp;其中，$I_{(parent)}$是父结点的不纯度度量，$k$是划分属性取值的个数。$N$是父亲结点上样本的总数，$N(j)$是第$j$个儿子结点上样本的数目，$I(j)$是第$j$个儿子节点的不纯度度量。\n",
    "\n",
    "&emsp;&emsp;给定任意结点$t$，如何来定义它的不纯度度量？令$p(i)$为结点$t$中第$i$类样本所占有的比例，则结点$t$的不纯度度量主要包括三种方式：熵、基尼指数、误分类率。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5da867a",
   "metadata": {},
   "source": [
    "### 划分选择"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef66451",
   "metadata": {},
   "source": [
    "1. 信息增益(`ID3`)：**熵**：\n",
    "\n",
    "$$\n",
    "Entropy(t) = -\\sum_{i=1}^{c}p(i)log_{2}p(i)\n",
    "$$\n",
    "\n",
    "&emsp;&emsp;**熵减最大**：\n",
    "\n",
    "$$\n",
    "\\Delta_{Entropy Reduction} = Entropy(parent) - \\sum_{j=1}^{k} \\frac{N(j)}{N}Entropy(j)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19e2d87",
   "metadata": {},
   "source": [
    "2. 信息增益率(`C4.5`)\n",
    "\n",
    "&emsp;&emsp;如果以信息增益率为划分依据，存在偏向选择**特征取值较多的特征**，信息增益比是对这一问题进行矫正。比如划分用户的时候，依据用户`ID`划分的话，只需要一层决策树就够了。\n",
    "\n",
    "$$\n",
    "GainRatio = \\frac{\\Delta_{info}}{SplitInfo}\n",
    "$$\n",
    "\n",
    "&emsp;&emsp;其中，$SplitInfo$是划分属性的分裂信息。其数学表达如下所示：\n",
    "\n",
    "$$\n",
    "SplitInfo = -\\sum_{j=1}^{k}p(j)log_{2}p(j)\n",
    "$$\n",
    "\n",
    "&emsp;&emsp;其中，$p(j)$是**当前结点中划分属性第$j$个属性值所占有样本的比例**。**分裂信息$SplitInfo$度量了属性划分数据的广度和均匀性**。分裂信息实际上就是当前结点关于划分属性各值的熵，它可以阻碍选择属性值均匀分布的属性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fbf766",
   "metadata": {},
   "source": [
    "3. 基尼系数：**基尼指数**：\n",
    "\n",
    "$$\n",
    "Gini(t)=1-\\sum_{i=1}^{c}p(i)^{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb055cb",
   "metadata": {},
   "source": [
    "### 剪枝处理\n",
    "\n",
    "- 预剪枝\n",
    "\n",
    "- 后剪枝\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c35b00b",
   "metadata": {},
   "source": [
    "### 连续与缺失值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33f6734",
   "metadata": {},
   "source": [
    "## 其他\n",
    "\n",
    "- 多变量决策树\n",
    "\n",
    "- 经典决策树算法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8c3f7c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17b12f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ef2c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
